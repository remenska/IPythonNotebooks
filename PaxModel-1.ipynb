{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rootpy.stl as stl\n",
    "stl.generate(\"Peak\",\"Peak.h\", True) # can be done for all elements of the data_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import types\n",
    "import inspect\n",
    "import traceback\n",
    "from rootpy.tree import IntCol, FloatCol, BoolCol, ObjectCol, LongCol, IntArrayCol, BoolArrayCol\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from rootpy.tree import TreeBuffer\n",
    "from pax.data_model import StrictModel,Model,ListField\n",
    "from rootpy.tree import TreeModel\n",
    "from pax.utils import Memoize\n",
    "import json\n",
    "import bson\n",
    "import rootpy.stl as stl\n",
    "import cppyy\n",
    "import ROOT\n",
    "\n",
    "# ROOT.gROOT.ProcessLine('.L pax_event_class.cpp+')\n",
    "# ROOT.gInterpreter.GenerateDictionary(\"Peak\",\"pax_event_class.h\")\n",
    "# ROOT.gInterpreter.GenerateDictionary(\"Interaction\",\"pax_event_class.h\")\n",
    "\n",
    "casting_allowed_for = {\n",
    "    int:    ['int16', 'int32', 'int64', 'Int64', 'Int32'],\n",
    "    float:  ['int', 'float32', 'float64', 'int16', 'int32', 'int64', 'Int64', 'Int32'],\n",
    "    bool:   ['int16', 'int32', 'int64', 'Int64', 'Int32'],\n",
    "    stl.string:    ['str'],\n",
    "    ROOT.vector(int): ['list'],\n",
    "    ROOT.vector(float): ['list'],\n",
    "    ROOT.vector(bool): ['list'],\n",
    "    ROOT.vector(stl.string): ['list'],\n",
    "    ROOT.vector(ROOT.Peak): ['list']\n",
    "}\n",
    "\n",
    "    \n",
    "class PaxTreeBuffer(TreeBuffer):\n",
    "    def __post_init__(self, kwargs_dict=None, quick_init=False, **kwargs):\n",
    "        if quick_init:\n",
    "            self.__dict__.update(kwargs_dict)\n",
    "            self.__dict__.update(kwargs)\n",
    "            return\n",
    "\n",
    "        # Initialize the collection fields to empty lists\n",
    "        # super() is needed to bypass type checking in StrictModel\n",
    "        list_field_info = self.get_list_field_info()\n",
    "        for field_name in list_field_info:\n",
    "            super().__setattr__(field_name, [])\n",
    "\n",
    "        # Initialize all attributes from kwargs and kwargs_dict\n",
    "        kwargs.update(kwargs_dict or {})\n",
    "        for k, v in kwargs.items():\n",
    "            if k in list_field_info:\n",
    "                # User gave a value to initialize a list field. Hopefully an iterable!\n",
    "                # Let's check if the types are correct\n",
    "                desired_type = list_field_info[k]\n",
    "                temp_list = []\n",
    "                for el in v:\n",
    "                    if isinstance(el, desired_type):\n",
    "                        # Good, pass through unmolested\n",
    "                        temp_list.append(el)\n",
    "                    elif isinstance(el, dict):\n",
    "                        # Dicts are fine too, we can use them to init the desired type\n",
    "                        temp_list.append(desired_type(**el))\n",
    "                    else:\n",
    "                        raise ValueError(\"Attempt to initialize list field %s with type %s, \"\n",
    "                                         \"but you promised type %s in class declaration.\" % (k,\n",
    "                                                                                             type(el),\n",
    "                                                                                             desired_type))\n",
    "                # This has to be a list of dictionaries\n",
    "                # suitable to be passed to __init__ of the list field's element type\n",
    "                setattr(self, k, temp_list)\n",
    "            else:\n",
    "                default_value = getattr(self, k)\n",
    "                if type(default_value) == np.ndarray:\n",
    "                    if isinstance(v, np.ndarray):\n",
    "                        pass\n",
    "                    elif isinstance(v, bytes):\n",
    "                        # Numpy arrays can be also initialized from a 'string' of bytes...\n",
    "                        v = np.fromstring(v, dtype=default_value.dtype)\n",
    "                    elif hasattr(v, '__iter__'):\n",
    "                        # ... or an iterable\n",
    "                        v = np.array(v, dtype=default_value.dtype) # TODO: rootpy.tree.treetypes.IntArray should pass here\n",
    "                    else:\n",
    "                        raise ValueError(\"Can't initialize field %s: \"\n",
    "                                         \"don't know how to make a numpy array from a %s\" % (k, type(v)))\n",
    "                elif isinstance(default_value, Model):\n",
    "                    v = default_value.__class__(**v)\n",
    "                elif isinstance(v, stl.string): \n",
    "                    v = str(v)                    \n",
    "                elif isinstance(v, stl.vector(stl.string)):\n",
    "                    if not v.empty():\n",
    "                        v = [str(el) for el in v]\n",
    "                    else:\n",
    "                        v = []  \n",
    "                elif isinstance(v, (stl.vector(int),\n",
    "                                   stl.vector(float),\n",
    "                                   stl.vector(bool),\n",
    "                                   stl.vector(Peak)\n",
    "                               )):\n",
    "                    if not v.empty():\n",
    "                        v = list(v)\n",
    "                    else:\n",
    "                        v = []\n",
    "\n",
    "                setattr(self, k, v)\n",
    "\n",
    "    def to_json(self, fields_to_ignore=None):\n",
    "        return json.dumps(self.to_dict(convert_numpy_arrays_to='list',\n",
    "                                       fields_to_ignore=fields_to_ignore)\n",
    "#                           , cls=ROOTJSONEncoder\n",
    "                         )\n",
    "\n",
    "    def to_bson(self, fields_to_ignore=None):\n",
    "        return bson.BSON.encode(self.to_dict(convert_numpy_arrays_to='bytes',\n",
    "                                             fields_to_ignore=fields_to_ignore))\n",
    "\n",
    "    def __setattr__(self, key, value): \n",
    "        # Get the old attr.\n",
    "        # #Will raise AttributeError if doesn't exists, which is what we want\n",
    "        if(key.startswith('_')): # TreeBuffer attributes for the ROOT tree\n",
    "            super().__setattr__(key, value)\n",
    "            \n",
    "        # model fields    \n",
    "        old_val = getattr(self, key)\n",
    "        old_type = type(old_val)\n",
    "        new_type = type(value)\n",
    "        # Check for attempted type change\n",
    "        if old_type != new_type:\n",
    "\n",
    "            # Are we allowed to cast the type?\n",
    "            if old_type in casting_allowed_for \\\n",
    "                    and value.__class__.__name__ in casting_allowed_for[old_type]:\n",
    "                if(old_type in [stl.vector(int), stl.vector(bool), stl.vector(float), \n",
    "                                stl.vector(stl.string),stl.vector(Peak)]):\n",
    "                    prev_value = value\n",
    "                    value=old_type()\n",
    "                    for el in prev_value: # TODO: more efficient way to populate the stl.vector\n",
    "                          value.push_back(str(el) if(old_type==stl.vector(stl.string)) else el)\n",
    "                else:    \n",
    "                    value = old_type(value)\n",
    "            else:\n",
    "                raise TypeError('Attribute %s of class %s should be a %s, not a %s. '\n",
    "                                % (key,\n",
    "                                   self.__class__.__name__,\n",
    "                                   old_val.__class__.__name__,\n",
    "                                   value.__class__.__name__))\n",
    "\n",
    "        # Check for attempted dtype change\n",
    "        if isinstance(old_val, np.ndarray):\n",
    "            if old_val.dtype != value.dtype:\n",
    "                raise TypeError('Attribute %s of class %s should have numpy dtype %s, not %s' % (\n",
    "                    key, self.__class__.__name__, old_val.dtype, value.dtype))\n",
    "                \n",
    "        super().__setattr__(key, value)\n",
    "    \n",
    "                \n",
    "#     @classmethod        # Use only in initialization (or if attributes are fixed, as for StrictModel)\n",
    "#     @Memoize            # Caching decorator, improves performance if a model is initialized often\n",
    "    def get_list_field_info(self):\n",
    "        \"\"\"Return dict with fielname => type of elements in collection fields in this class\n",
    "        \"\"\"\n",
    "        list_field_info = {}\n",
    "        for k, v in self.get_fields_data():\n",
    "            if isinstance(v, ListField):\n",
    "                list_field_info[k] = v.element_type\n",
    "        return list_field_info\n",
    "    \n",
    "    def __str__(self): #TODO change\n",
    "        return str(self.__dict__['_OrderedDict__map'])\n",
    "    \n",
    "    def get_fields_data(self):\n",
    "        \"\"\"Iterator over (key, value) tuples of all user-specified fields\n",
    "        Returns keys in lexical order\n",
    "        \"\"\"\n",
    "        # TODO: increase performance by pre-sorting keys?\n",
    "        # self.__dict__.items() does not return default values set in class declaration\n",
    "        # Hence we need something more complicated\n",
    "        class_dict = self.__dict__['_OrderedDict__map']\n",
    "        self_dict = self.__dict__\n",
    "        \n",
    "        for field_name in sorted(class_dict.keys()):\n",
    "            if field_name in self_dict:\n",
    "                # The instance has a value for this field: return it\n",
    "                yield (field_name, self_dict[field_name])\n",
    "            else:\n",
    "                # ... it doesnt. Should we return its value?\n",
    "                if field_name.startswith('_'):\n",
    "                    continue    # No, is internal\n",
    "                value_in_class = self.__getattr__(field_name) #TODO: or __getitem (returns wrapper object)\n",
    "                if callable(value_in_class):\n",
    "                    continue    # No, is a method\n",
    "                if isinstance(value_in_class, (property, classmethod)):\n",
    "                    continue    # No, is a property or classmethod\n",
    "                # Yes, yield the class-level value\n",
    "                yield (field_name, value_in_class)\n",
    "    \n",
    "    def to_dict(self, convert_numpy_arrays_to=None, fields_to_ignore=None):\n",
    "        # TODO deal with rootpy.tree.treetypes.IntArray etc types\n",
    "        result = {}\n",
    "        if fields_to_ignore is None:\n",
    "            fields_to_ignore = tuple()\n",
    "        for k, v in self.get_fields_data():\n",
    "            if k in fields_to_ignore:\n",
    "                continue\n",
    "            if isinstance(v, PaxTreeBuffer):\n",
    "                result[k] = v.to_dict(convert_numpy_arrays_to=convert_numpy_arrays_to,\n",
    "                                      fields_to_ignore=fields_to_ignore)\n",
    "            elif isinstance(v, list):\n",
    "                result[k] = [el.to_dict(convert_numpy_arrays_to=convert_numpy_arrays_to,\n",
    "                                        fields_to_ignore=fields_to_ignore) for el in v]\n",
    "            # dealing with ROOT stl.string fields\n",
    "            elif isinstance(v, stl.string):\n",
    "                result[k] = str(v)\n",
    "            # dealing with ROOT.vectors\n",
    "            elif isinstance(v, (stl.vector(int),\n",
    "                               stl.vector(float),\n",
    "                               stl.vector(bool)\n",
    "#                                stl.vector(Peak)\n",
    "                               )):\n",
    "                if not v.empty():\n",
    "                    result[k] = list(v)\n",
    "                else:\n",
    "                    result[k] = []\n",
    "            elif isinstance(v, stl.vector(stl.string)):\n",
    "                if not v.empty():\n",
    "                    result[k] = [str(el) for el in v]\n",
    "                else:\n",
    "                    result[k] = []\n",
    "            elif isinstance(v, ROOT.ObjectProxy): \n",
    "                if hasattr(v, 'value_type'): # Its stl.vector of ROOT.* object\n",
    "                    list_result = []\n",
    "                    for el in v:\n",
    "                        dict_el = {}\n",
    "                        for key in eval(v.value_type).__dict__.keys():\n",
    "                            if key not in ['__doc__', '__module__']:\n",
    "                                dict_el[key] = el.__getattribute__(key)\n",
    "                        list_result.append(dict_el)\n",
    "                        result[k] = list_result\n",
    "                        \n",
    "#                       result[k] = [key for key in eval(v.value_type).__dict__.keys()]\n",
    "            elif isinstance(v, np.ndarray) and convert_numpy_arrays_to is not None:\n",
    "                if convert_numpy_arrays_to == 'list':\n",
    "                    result[k] = v.tolist()\n",
    "                elif convert_numpy_arrays_to == 'bytes':\n",
    "                    result[k] = v.tostring()\n",
    "                else:\n",
    "                    raise ValueError('convert_numpy_arrays_to must be \"list\" or \"bytes\"')\n",
    "            else:\n",
    "                result[k] = v\n",
    "        return result\n",
    "    \n",
    "class ROOTModel(StrictModel):\n",
    "    def __new__(cls, kwargs_dict=None, quick_init=False, **kwargs):\n",
    "        treebuffer = PaxTreeBuffer()\n",
    "        for name, attr in cls.get_attrs():\n",
    "            treebuffer[name] = attr()\n",
    "\n",
    "        treebuffer.__post_init__(kwargs_dict, quick_init, **kwargs) # We need TreeBuffer to have to_dict, to_json...   \n",
    "        return treebuffer\n",
    "        \n",
    "EventModel = type(\"EventModel\", (TreeModel,), {'__new__':ROOTModel.__new__})\n",
    "\n",
    "INT_NAN = -99999\n",
    "\n",
    "# from ROOT import TObject,TClonesArray,AddressOf, TRef\n",
    "# from rootpy.tree.model import TreeModelMeta\n",
    "\n",
    "class Peak(ROOT.Peak):\n",
    "    n_hits = IntCol(0)\n",
    "    hits_fraction_top = FloatCol(1.1)\n",
    "    \n",
    "class Event(EventModel):\n",
    "    dataset_name = stl.string\n",
    "    event_number = IntCol(0)\n",
    "    n_channels = IntCol(INT_NAN)\n",
    "    start_time = LongCol(0)\n",
    "    stop_time = LongCol(0)\n",
    "    sample_duration = IntCol(0)\n",
    "    peaks = stl.vector(Peak)\n",
    "#     is_channel_suspicious = BoolArrayCol(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peak1 = ROOT.Peak()\n",
    "peak1.n_hits = 33\n",
    "peak2 = ROOT.Peak()\n",
    "peak2.n_hits = 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# or don't populate\n",
    "event = Event(dataset_name=\"dataset1\", event_number=999)\n",
    "event.peaks.push_back(peak1)\n",
    "event.peaks.push_back(peak2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'dataset1',\n",
       " 'event_number': 999,\n",
       " 'n_channels': -99999,\n",
       " 'peaks': [{'hits_fraction_top': 11.100000381469727, 'n_hits': 11},\n",
       "  {'hits_fraction_top': 22.200000762939453, 'n_hits': 22}],\n",
       " 'sample_duration': 0,\n",
       " 'start_time': 0,\n",
       " 'stop_time': 0}"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "event.peaks[0].hits_fraction_top = 11.1\n",
    "event.peaks[0].n_hits = 11\n",
    "event.peaks[1].hits_fraction_top = 22.2\n",
    "event.peaks[1].n_hits = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'dataset1',\n",
       " 'event_number': 999,\n",
       " 'n_channels': -99999,\n",
       " 'peaks': [{'hits_fraction_top': 11.100000381469727, 'n_hits': 11},\n",
       "  {'hits_fraction_top': 22.200000762939453, 'n_hits': 22}],\n",
       " 'sample_duration': 0,\n",
       " 'start_time': 0,\n",
       " 'stop_time': 0}"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peak1.something = 4 # NOPE, should not be allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event.peaks[1].n_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ROOT.TTree.Bronch:Using split mode on a class: Peak with a custom Streamer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ROOT.TBranchElement object (\"dataset_name\") at 0x765fce0>\n",
      "<ROOT.TBranchElement object (\"peaks\") at 0x7514560>\n",
      "<ROOT.TBranch object (\"event_number\") at 0x74b9480>\n",
      "<ROOT.TBranch object (\"n_channels\") at 0x7d97910>\n",
      "<ROOT.TBranch object (\"start_time\") at 0x7599970>\n",
      "<ROOT.TBranch object (\"stop_time\") at 0x75ba4c0>\n",
      "<ROOT.TBranch object (\"sample_duration\") at 0x74fe020>\n"
     ]
    }
   ],
   "source": [
    "# usse the model to write a ROOT tree\n",
    "from rootpy.tree import Tree, Ntuple, TreeModel, TreeChain\n",
    "from rootpy.tree.treetypes import *\n",
    "from rootpy.tree.tree import *\n",
    "from rootpy.tree.model import *\n",
    "import ROOT\n",
    "import rootpy.stl as stl\n",
    "from ROOT import Peak \n",
    "from rootpy.io import root_open, TemporaryFile\n",
    "f = root_open(\"test_pax_new.root\", \"recreate\")\n",
    "\n",
    "tree_event = Tree(\"events\", \"events\", model=Event)\n",
    "tree_event.event_number = 55\n",
    "tree_event.dataset_name = \"sdsd\"\n",
    "\n",
    "peak1 = Peak()\n",
    "peak1.n_hits = 22\n",
    "peak1.hits_fraction_top = 22.22\n",
    "peak2 = Peak()\n",
    "peak2.n_hits = 33\n",
    "peak2.hits_fraction_top = 33.33\n",
    "tree_event.peaks.push_back(peak1)\n",
    "tree_event.peaks.push_back(peak2)\n",
    "tree_event.fill() \n",
    "# tree_event.write()\n",
    "\n",
    "f.write()\n",
    "\n",
    "for branch in tree_event.GetListOfBranches():\n",
    "    print(branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
